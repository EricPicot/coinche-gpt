### Necessity to predict scores 

By choosing randomly the atout suit, and by playing with random players, it seems very hard to be able to learn descent 
strategies. Given their hands, the team players could, by playing randomly and given the atout suit be able to win a 
total reward of 30 and given other hands a total reward of 150. 

Using *_generate_database.py_*, we can easily run thousands of random round to create a dataset of initial hands and of
reward gained playing randomly.

The idea of this part of the project is to be able to determine to potential of the hand of a player (or the hanfs of a
 team) to modify the atout suit when launching experiments using RL Coach.
 
 We therefore hope that because the AI plays "interesting" rounds, it will find better strategies